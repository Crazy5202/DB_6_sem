{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121736/782615467.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df = pd.concat([result_df, chunk], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100000 rows...\n",
      "Processed 200000 rows...\n",
      "Processed 300000 rows...\n",
      "Processed 400000 rows...\n",
      "Processed 500000 rows...\n",
      "Processed 600000 rows...\n",
      "Processed 700000 rows...\n",
      "Processed 800000 rows...\n",
      "Processed 900000 rows...\n",
      "Processed 1000000 rows...\n",
      "Processed 1100000 rows...\n",
      "Processed 1200000 rows...\n",
      "Processed 1300000 rows...\n",
      "Processed 1400000 rows...\n",
      "Processed 1500000 rows...\n",
      "Processed 1600000 rows...\n",
      "Processed 1700000 rows...\n",
      "Processed 1800000 rows...\n",
      "Processed 1900000 rows...\n",
      "Processed 2000000 rows...\n",
      "Processed 2100000 rows...\n",
      "Processed 2200000 rows...\n",
      "Processed 2300000 rows...\n",
      "Processed 2400000 rows...\n",
      "Processed 2500000 rows...\n",
      "Processed 2600000 rows...\n",
      "Processed 2700000 rows...\n",
      "Processed 2800000 rows...\n",
      "Processed 2900000 rows...\n",
      "Processed 3000000 rows...\n",
      "Processed 3100000 rows...\n",
      "Processed 3200000 rows...\n",
      "Processed 3300000 rows...\n",
      "Processed 3400000 rows...\n",
      "Processed 3500000 rows...\n",
      "Processed 3600000 rows...\n",
      "Processed 3700000 rows...\n",
      "Processed 3800000 rows...\n",
      "Processed 3900000 rows...\n",
      "Processed 4000000 rows...\n",
      "Processed 4100000 rows...\n",
      "Processed 4200000 rows...\n",
      "Processed 4300000 rows...\n",
      "Processed 4400000 rows...\n",
      "Processed 4500000 rows...\n",
      "Processed 4600000 rows...\n",
      "Processed 4700000 rows...\n",
      "Processed 4800000 rows...\n",
      "Processed 4900000 rows...\n",
      "Processed 5000000 rows...\n",
      "Processed 5100000 rows...\n",
      "Processed 5200000 rows...\n",
      "Processed 5300000 rows...\n",
      "Processed 5400000 rows...\n",
      "Processed 5500000 rows...\n",
      "Processed 5600000 rows...\n",
      "Processed 5700000 rows...\n",
      "Processed 5800000 rows...\n",
      "Processed 5900000 rows...\n",
      "Processed 6000000 rows...\n",
      "Processed 6100000 rows...\n",
      "Processed 6200000 rows...\n",
      "Processed 6300000 rows...\n",
      "Processed 6400000 rows...\n",
      "Processed 6500000 rows...\n",
      "Processed 6600000 rows...\n",
      "Processed 6700000 rows...\n",
      "Processed 6800000 rows...\n",
      "Processed 6900000 rows...\n",
      "Processed 7000000 rows...\n",
      "Processed 7100000 rows...\n",
      "Processed 7200000 rows...\n",
      "Processed 7300000 rows...\n",
      "Processed 7400000 rows...\n",
      "Processed 7500000 rows...\n",
      "Processed 7600000 rows...\n",
      "Processed 7700000 rows...\n",
      "Processed 7800000 rows...\n",
      "Processed 7900000 rows...\n",
      "Processed 8000000 rows...\n",
      "Processed 8100000 rows...\n",
      "Processed 8200000 rows...\n",
      "Processed 8300000 rows...\n",
      "Processed 8400000 rows...\n",
      "Processed 8500000 rows...\n",
      "Processed 8600000 rows...\n",
      "Processed 8700000 rows...\n",
      "Processed 8800000 rows...\n",
      "Processed 8900000 rows...\n",
      "Processed 9000000 rows...\n",
      "Processed 9100000 rows...\n",
      "Processed 9200000 rows...\n",
      "Processed 9300000 rows...\n",
      "Processed 9400000 rows...\n",
      "Processed 9500000 rows...\n",
      "Processed 9600000 rows...\n",
      "Processed 9700000 rows...\n",
      "Processed 9800000 rows...\n",
      "Processed 9900000 rows...\n",
      "Processed 10000000 rows...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = 'steam_reviews.csv'\n",
    "output_file = 'filtered_data.csv'\n",
    "\n",
    "# Columns you want to keep\n",
    "columns_to_keep = ['review_id', 'app_name', 'recommended', 'weighted_vote_score', 'timestamp_created']  # Replace with your column names\n",
    "\n",
    "# Number of rows to keep\n",
    "rows_to_keep = int(1e7)\n",
    "\n",
    "# Initialize a counter\n",
    "rows_processed = 0\n",
    "\n",
    "# Create an empty DataFrame to store results\n",
    "result_df = pd.DataFrame(columns=columns_to_keep)\n",
    "\n",
    "# Read the CSV in chunks\n",
    "chunk_size = int(1e5)  # Adjust based on your memory availability\n",
    "for chunk in pd.read_csv(input_file, chunksize=chunk_size, usecols=columns_to_keep):\n",
    "    # Calculate how many rows we need from this chunk\n",
    "    remaining_rows = rows_to_keep - rows_processed\n",
    "    if remaining_rows <= 0:\n",
    "        break\n",
    "    \n",
    "    # Take only the needed rows from this chunk\n",
    "    chunk = chunk.head(remaining_rows)\n",
    "    \n",
    "    # Append to result\n",
    "    result_df = pd.concat([result_df, chunk], ignore_index=True)\n",
    "    \n",
    "    # Update counter\n",
    "    rows_processed += len(chunk)\n",
    "    print(f\"Processed {rows_processed} rows...\")\n",
    "    \n",
    "    # Early exit if we've got enough rows\n",
    "    if rows_processed >= rows_to_keep:\n",
    "        break\n",
    "\n",
    "# Save to new CSV file\n",
    "result_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved {len(result_df)} rows to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def get_sample(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df['timestamp_created'] = df['timestamp_created'].apply(lambda ts: datetime.fromtimestamp(ts))\n",
    "    df.to_csv('ready.csv', index=False)\n",
    "\n",
    "#get_sample('sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df.sort_values('timestamp_created', inplace=True)\n",
    "    df.to_csv(f'{filename}_asc.csv', index=False)\n",
    "\n",
    "#sort_df('ready.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
